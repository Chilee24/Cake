import torch
import torch.nn as nn
import pytorchvideo.models.x3d as x3d
import logging
import copy
from odconv3d import ODConv3d

class FlowHallucinationBlock(nn.Module):
    def __init__(self, in_channels):
        super(FlowHallucinationBlock, self).__init__()
        self.time_odconv = ODConv3d(in_planes=in_channels, out_planes=in_channels, 
                                    kernel_size=(3, 1, 1), padding=(1, 0, 0), 
                                    reduction=0.0625, kernel_num=4)
        self.bn1 = nn.BatchNorm3d(in_channels)
        self.act1 = nn.SiLU(inplace=True)

        self.space_odconv = ODConv3d(in_planes=in_channels, out_planes=in_channels, 
                                     kernel_size=(1, 3, 3), padding=(0, 1, 1), 
                                     reduction=0.0625, kernel_num=1)
        self.bn2 = nn.BatchNorm3d(in_channels)
        self.act_final = nn.SiLU(inplace=True)

    def forward(self, x):
        #residual = x 
        out = self.time_odconv(x)
        out = self.bn1(out)
        out = self.act1(out)
        out = self.space_odconv(out)
        out = self.bn2(out)
        #out += residual 
        out = self.act_final(out)
        return out

# ==================================================================
# BIO-X3D STUDENT (Updated with Output Flag)
# ==================================================================
class BioX3D_Student(nn.Module):
    def __init__(self, clip_len=13, feature_dim=192, num_classes=400):
        super(BioX3D_Student, self).__init__()
        
        print(f"üõ†Ô∏è Kh·ªüi t·∫°o BioX3D Student...")
        
        # 1. T·∫°o X3D chu·∫©n
        full_x3d = x3d.create_x3d(
            input_channel=3, 
            input_clip_length=clip_len, 
            model_num_class=num_classes,
            head_activation=None
        )
        modules = list(full_x3d.blocks.children())
        
        # --- NH√ÅNH RGB (PRIMARY) ---
        self.blocks = nn.Sequential(*modules[:-1]) # Backbone tr·∫£ v·ªÅ (B, 192, T, H, W)
        self.head = modules[-1]                    # Head
        del full_x3d


        # self.flow_adapter = nn.Sequential(
        #     nn.Conv3d(feature_dim, feature_dim, kernel_size=1, bias=False),
        #     nn.BatchNorm3d(feature_dim),
        #     nn.ReLU(inplace=True)
        # )

        # self.flow_adapter = nn.Sequential(
        #     nn.Conv3d(feature_dim, feature_dim // 4, kernel_size=1, bias=False),
        #     nn.BatchNorm3d(feature_dim // 4),
        #     nn.ReLU(inplace=True),
        #     nn.Conv3d(feature_dim // 4, feature_dim, kernel_size=1, bias=False),
        #     nn.BatchNorm3d(feature_dim),
        #     nn.ReLU(inplace=True)
        # )
        
        self.flow_adapter = nn.Sequential(
            # 1. Depthwise ODConv3d: Thu th·∫≠p th√¥ng tin chuy·ªÉn ƒë·ªông (Context)
            # - Kernel (3,3,3): Gi√∫p pixel nh√¨n ƒë∆∞·ª£c l√¢n c·∫≠n kh√¥ng gian v√† th·ªùi gian (frame tr∆∞·ªõc/sau).
            # - groups=feature_dim: Ch√¨a kh√≥a ƒë·ªÉ l√†m n√≥ nh·∫π (Depthwise).
            ODConv3d(
                in_planes=feature_dim, 
                out_planes=feature_dim, 
                kernel_size=(3, 3, 3), 
                stride=1, 
                padding=(1, 1, 1), 
                reduction=0.0625, 
                kernel_num=1,
                groups=feature_dim # <--- QUAN TR·ªåNG: Bi·∫øn n√≥ th√†nh Depthwise
            ),
            nn.BatchNorm3d(feature_dim),
            nn.ReLU(inplace=True),

            # 2. Pointwise ODConv3d: Tr·ªôn th√¥ng tin gi·ªØa c√°c k√™nh (Channel Mixing)
            # Sau khi m·ªói k√™nh ƒë√£ t·ª± nh√¨n h√†ng x√≥m (b∆∞·ªõc 1), b∆∞·ªõc n√†y gi√∫p c√°c k√™nh giao ti·∫øp v·ªõi nhau.
            ODConv3d(
                in_planes=feature_dim, 
                out_planes=feature_dim, 
                kernel_size=(1, 1, 1), 
                stride=1, 
                padding=0, 
                reduction=0.0625, 
                kernel_num=1
            ),
            nn.BatchNorm3d(feature_dim),
            nn.ReLU(inplace=True)
        )

        self.hallucinator = FlowHallucinationBlock(feature_dim)
        self.flow_head = copy.deepcopy(self.head)

    def _extract_embedding(self, feat_map, head_module):
        """Helper ƒë·ªÉ l·∫•y vector 2048 chi·ªÅu"""
        vec = head_module.pool(feat_map)
        vec = head_module.output_pool(vec)
        vec = vec.flatten(1)
        return vec

    def forward(self, x, return_embeddings=False):
        """
        Args:
            x: Input tensor (B, 3, T, H, W)
            return_embeddings (bool): 
                - False (Default): Tr·∫£ v·ªÅ 4 output (Logits, FeatMap)
                - True: Tr·∫£ v·ªÅ 6 output (Logits, FeatMap, Embeddings 2048)
        """
        # 1. RGB Path
        rgb_feat_map = self.blocks(x) 
        rgb_logits = self.head(rgb_feat_map)
        
        # 2. Flow Path
        flow_feat_pre = self.flow_adapter(rgb_feat_map)
        flow_hallucinated = self.hallucinator(flow_feat_pre)
        flow_logits = self.flow_head(flow_hallucinated)
        
        # --- Logic tr·∫£ v·ªÅ ---
        if return_embeddings:
            # T√≠nh th√™m embeddings 2048 chi·ªÅu
            rgb_embed = self._extract_embedding(rgb_feat_map, self.head)
            flow_embed = self._extract_embedding(flow_hallucinated, self.flow_head)
            
            # Tr·∫£ v·ªÅ 6 gi√° tr·ªã
            return rgb_logits, flow_logits, rgb_feat_map, flow_hallucinated, rgb_embed, flow_embed
        else:
            # M·∫∑c ƒë·ªãnh: Tr·∫£ v·ªÅ 4 gi√° tr·ªã
            return rgb_logits, flow_logits, rgb_feat_map, flow_hallucinated
            
    def load_pretrained_weights(self, rgb_path, flow_teacher_path=None):
        """
        H√†m load weight th√¥ng minh:
        1. Load RGB Weights v√†o self.blocks v√† self.head
        2. Load Flow Teacher Weights v√†o self.flow_head (n·∫øu c√≥)
        """
        # --- 1. LOAD RGB (STUDENT PRETRAINED) ---
        if rgb_path:
            logging.info(f"üì• Loading RGB weights: {rgb_path}")
            try:
                ckpt = torch.load(rgb_path, map_location='cpu')
                # L·∫•y state_dict chu·∫©n
                if 'model_state' in ckpt: state = ckpt['model_state']
                elif 'state_dict' in ckpt: state = ckpt['state_dict']
                else: state = ckpt
                
                rgb_dict = {}
                for k, v in state.items():
                    # Map Head g·ªëc (blocks.5) -> self.head
                    if k.startswith("blocks.5"):
                        new_key = k.replace("blocks.5", "head")
                        rgb_dict[new_key] = v
                    # Map Backbone (blocks.0-4) -> self.blocks
                    elif k.startswith("blocks"):
                        rgb_dict[k] = v
                    # B·ªè qua c√°c key kh√¥ng li√™n quan
                
                msg = self.load_state_dict(rgb_dict, strict=False)
                logging.info(f"‚úÖ RGB Backbone & Head Loaded: {msg}")
            except Exception as e:
                logging.error(f"‚ùå Failed to load RGB weights: {e}")

        # --- 2. LOAD FLOW HEAD (TEACHER WEIGHTS) ---
        if flow_teacher_path:
            logging.info(f"üì• Loading FLOW Head from Teacher: {flow_teacher_path}")
            try:
                t_ckpt = torch.load(flow_teacher_path, map_location='cpu')
                t_state = t_ckpt['model_state'] if 'model_state' in t_ckpt else (t_ckpt['state_dict'] if 'state_dict' in t_ckpt else t_ckpt)
                
                # L·ªçc l·∫•y weight c·ªßa Head t·ª´ Teacher (blocks.5) v√† nh√©t v√†o flow_head
                flow_head_dict = {}
                count = 0
                for k, v in t_state.items():
                    # T√¨m layer thu·ªôc Head trong file teacher
                    if "blocks.5" in k or "head" in k: 
                        # Map sang t√™n bi·∫øn c·ªßa Student: 'flow_head'
                        # Logic replace n√†y c·∫ßn linh ho·∫°t t√πy t√™n trong checkpoint teacher
                        if "blocks.5" in k:
                            new_key = k.replace("blocks.5", "flow_head")
                        elif "head" in k:
                            new_key = k.replace("head", "flow_head")
                        
                        # Ch·ªâ l·∫•y nh·ªØng layer kh·ªõp t√™n v·ªõi self.flow_head
                        # (V√≠ d·ª•: flow_head.proj.weight)
                        flow_head_dict[new_key] = v
                        count += 1
                
                if count > 0:
                    msg = self.load_state_dict(flow_head_dict, strict=False)
                    logging.info(f"‚úÖ Flow Head Loaded ({count} params)! Student ƒë√£ k·∫ø th·ª´a tri th·ª©c ph√¢n lo·∫°i c·ªßa Teacher.")
                else:
                    logging.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y layer Head ph√π h·ª£p trong Flow Teacher Checkpoint.")
                    
            except Exception as e:
                logging.error(f"‚ùå Failed to load Flow Head: {e}")


# ==================================================================
# 3. TEST
# ==================================================================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    BATCH = 2
    FRAMES = 13
    
    try:
        model = BioX3D_Student(clip_len=FRAMES).to(device)
        print("\n‚úÖ Model created!")
        
        # Test input
        dummy = torch.randn(BATCH, 3, FRAMES, 224, 224).to(device)
        rgb_logits, flow_logits, rgb_feat, flow_feat = model(dummy)
        
        print(f"\nShape Check:")
        print(f"RGB Logits: {rgb_logits.shape} (Expect {BATCH}, 400)")
        print(f"Flow Logits: {flow_logits.shape} (Expect {BATCH}, 400)")
        print(f"Flow Feat: {flow_feat.shape} (Expect {BATCH}, 192, {FRAMES}, 7, 7)")
        
        print(f"\nüß™ Sanity Check (Logits vs Softmax):")
        sample_output = rgb_logits[0] # L·∫•y m·∫´u ƒë·∫ßu ti√™n
        print(f"   - Min val: {sample_output.min().item():.4f}")
        print(f"   - Max val: {sample_output.max().item():.4f}")
        print(f"   - Sum val: {sample_output.sum().item():.4f}")
        
        if abs(sample_output.sum().item() - 1.0) > 0.1:
             print("   ‚úÖ K·∫øt lu·∫≠n: Output l√† LOGITS (V√¨ t·ªïng != 1)")
        else:
             print("   ‚ö†Ô∏è K·∫øt lu·∫≠n: Output c√≥ th·ªÉ l√† SOFTMAX (V√¨ t·ªïng ~ 1)")
        
        if rgb_logits.shape == flow_logits.shape == (BATCH, 400):
            print("\nüéâ Verification Passed!")
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\n‚ùå Error: {e}")